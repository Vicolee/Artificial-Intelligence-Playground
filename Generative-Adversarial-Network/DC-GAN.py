# -*- coding: utf-8 -*-
"""DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14XkbrQyULdSKy1q--L7ApGPKgS4ghRiF
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras import layers, datasets, models
from tensorflow.keras.datasets import mnist
print(tf.__version__)

# Model input dimensions
img_rows = 28
img_cols = 28
channels = 1
img_shape = (img_rows, img_cols, channels)
z_dim = 100

# Build Generator model
def make_generator_model(z_dim):
  model = models.Sequential()
  model.add(layers.Dense(256*7*7, input_dim = z_dim))
  model.add(layers.LeakyReLU(alpha=0.01))
  model.add(layers.Reshape((7, 7, 256)))
  
  model.add(layers.Conv2DTranspose(filters = 128, kernel_size = 3, strides=2, padding='same'))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU(alpha=0.01))

  model.add(layers.Conv2DTranspose(filters=64, kernel_size=3, strides=1, padding='same'))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU(alpha=0.01))

  model.add(layers.Conv2DTranspose(filters=1, kernel_size=3, strides=2, padding='same', activation='tanh'))
  
  return model

# Build Discriminator model
def make_discriminator_model(img_shape):
  model = models.Sequential() 
  model.add(layers.Conv2D(32, kernel_size = 3, strides = 2, input_shape=img_shape, padding='same')) # 28 x 28 x 1 to 14 x 14 x 32
  model.add(layers.LeakyReLU(alpha=0.01))
  model.add(layers.Dropout(0.2))

  model.add(layers.Conv2D(64, kernel_size = 3, strides = 2, padding='same')) # 14 x 14 x 32 to 7 x 7 x 64
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU(alpha=0.01))
  model.add(layers.Dropout(0.2))

  model.add(layers.Conv2D(128, kernel_size = 3, strides = 2, padding='same'))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU(alpha=0.01))
  model.add(layers.Dropout(0.2))

  model.add(layers.Flatten())
  model.add(layers.Dense(1, activation='sigmoid'))

  return model

def make_gan_model(generator, discriminator):
  model = models.Sequential()
  model.add(generator)
  model.add(discriminator)
  return model

discriminator = make_discriminator_model(img_shape)
discriminator.compile(loss='binary_crossentropy',
                      optimizer = 'adam',
                      metrics = ['accuracy'])

generator = make_generator_model(z_dim)
discriminator.trainable = False
gan = make_gan_model(generator, discriminator)
gan.compile(loss='binary_crossentropy',
            optimizer = 'adam')

# DCGAN Training Loop
losses = []
accuracies = []
iteration_checkpoints = []

def train(iterations, batch_size, sample_interval):
  (X_train, y_train), (X_test, y_test) = mnist.load_data()
  X_train = X_train / 127.5 - 1.0
  X_train = np.expand_dims(X_train, axis=3)

  real = np.ones((batch_size, 1))
  fake = np.zeros((batch_size, 1))

  for iteration in range(iterations):
    idx = np.random.randint(0, X_train.shape[0], batch_size)
    imgs = X_train[idx]

    z = np.random.normal(0, 1, (batch_size, 100))
    gen_imgs = generator.predict(z)

    d_loss_real = discriminator.train_on_batch(imgs, real)
    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
    d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)

    z = np.random.normal(0, 1, (batch_size, 100))
    gen_imgs = generator.predict(z)

    g_loss = gan.train_on_batch(z, real) # Check this . Why is it z and not gen_imgs

    if (iteration+1) % sample_interval == 0:
      losses.append((d_loss, g_loss))
      accuracies.append(accuracy * 100.0)
      iteration_checkpoints.append(iteration + 1)

      print("%d [D loss: %f, acc: %.2f] [G loss: %f]" %
            (iteration + 1, d_loss, 100.0 * accuracy, g_loss))
      sample_images(generator)

def sample_images(generator, image_grid_rows=4, image_grid_columns=4):
  z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))
  gen_imgs = generator.predict(z)
  gen_imgs = 0.5 * gen_imgs + 0.5
  fig, axs = plt.subplots(image_grid_rows,
                          image_grid_columns,
                          figsize=(4,4),
                          sharey=True,
                          sharex=True)
  
  cnt = 0
  for i in range(image_grid_rows):
    for j in range(image_grid_columns):
      axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')
      axs[i, j].axis('off')
      cnt += 1

iterations = 20000
batch_size = 128
sample_interval = 1000
train(iterations, batch_size, sample_interval)

# save checkpoints
checkpoint_dir = './training_checkpoints'